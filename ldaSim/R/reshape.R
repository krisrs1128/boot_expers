#! /usr/bin/env Rscript

## File description -------------------------------------------------------------
## Functions for reshaping output from the LDA simulation.
##
## @author: kriss1@stanford.edu

#' Read true parameter values from file
#'
#' @param metadata [data.frame] The metadata data frame, including all paths to
#'   data generated by the simulation.
#' @param param [string] The name of the parameter to draw posterior samples for
#' @return truth [data.frame]
#' @importFrom dplyr filter select mutate left_join select_ starts_with
#' @importFrom reshape2 dcast
#' @importFrom magrittr %>%
#' @export
get_truth_data <- function(metadata, param, variable = "v") {
  truth_paths <- metadata %>%
    filter(
      is.na(method),
      grepl(param, file)
    ) %>%
    select(file) %>%
    unlist()

  feather_from_paths(truth_paths) %>%
    mutate(k = paste0("truth_", k)) %>%
    dcast(formula(sprintf("file + %s ~ k", variable))) %>%
    left_join(metadata) %>%
    select_(variable, ~starts_with("truth"), "D", "V", "K", "alpha0", "gamma0")
}

#' Combine posterior samples for a parameter
#'
#' This retrieves all posterior samples for a parameter, across many
#' experimental configurations.
#'
#' @param metadata [data.frame] The metadata data frame, including all paths to
#'   data generated by the simulation.
#' @param param [string] The name of the parameter to draw posterior samples for
#' @return samples [data.frame]
#' @importFrom dplyr filter select mutate starts_with
#' @importFrom data.table dcast
#' @export
get_samples <- function(metadata, param, var_names = NULL) {
  samples_paths <- metadata %>%
    filter(
      method %in% c("vb", "gibbs")
    ) %>%
    select(file) %>%
    unlist()

  rdata_from_paths(samples_paths, param, var_names) %>%
    mutate(k = paste0("value_", k)) %>%
    dcast(file + iteration + variable ~ k) %>%
    left_join(metadata, by = "file") %>%
    mutate(iteration = pmin(iteration.x, iteration.y, na.rm = TRUE)) %>%
    select(-file, -iteration.x, -iteration.y, -starts_with("alpha"), -starts_with("gamma"))
}

#' Combine bootstrap samples for a parameter
#'
#' This retrieves all posterior samples for a parameter, across many
#' experimental configurations.
#'
#' @param metadata [data.frame] The metadata data frame, including all paths to
#'   data generated by the simulation.
#' @param param [string] The name of the parameter to draw posterior samples for
#' @return bootstraps [data.frame]
#' @importFrom dplyr filter select mutate rename_ left_join starts_with
#' @importFrom data.table dcast
#' @export
get_bootstraps <- function(metadata, param, variable = "v") {
  bootstrap_paths <- metadata %>%
    filter(
      method == "bootstrap",
      grepl(param, file)
    ) %>%
    select(file) %>%
    unlist()

  feather_from_paths(bootstrap_paths) %>%
    mutate(k = paste0("value_", k)) %>%
    rename_(.dots = setNames(variable, "variable")) %>%
    dcast(file + variable ~ k) %>%
    left_join(metadata) %>%
    select(-file, -starts_with("alpha"), -starts_with("gamma"))
}

#' Identify a permutation that aligns rows of two matrices
#'
#' One way to get confidence intervals for mixtures on the simplex is
#' to first specify the cluster labels for each component, and then
#' study each of these histograms on their own. This is different
#' from, say, smoothing the mixture distribution and identifying
#' modes.
#'
#' The approach taken here is to find the two rows with maximal
#' correlation and put that in the required permutation. Then, remove
#' those rows and repeat.
#'
#' @param X [numeric matrix] A matrix whose rows we want to align with
#'   X.
#' @param Z [numeric matrix] A matrix whose rows we want to align with
#'   Z.
#' @return pi_result [vector] A permutation such that X[pi_result, ] = Z
#' (ideally).
#' @examples
#' X <- matrix(rnorm(100, mean = 4) ^ 2, 20, 5)
#' pi <- sample(1:20)
#' Z <- X[pi, ] + matrix(rnorm(100), 20, 5)
#' pi_hat <- match_matrix(X, Z)
#' cbind(pi_hat, pi)
#' @export
match_matrix <- function(X, Z) {
  n <- nrow(X)
  X_tilde <- X
  Z_tilde <- Z

  rownames(X_tilde) <- seq_len(n)
  rownames(Z_tilde) <- seq_len(n)
  pi_result <- rep(0, n)

  for (i in seq_len(n)) {
    # get maximal correlation in remainding rows
    rho <- cor(t(X_tilde), t(Z_tilde))
    max_ix0 <- which(rho == max(rho), arr.ind = TRUE)

    max_ix <- c(
      as.integer(rownames(X_tilde)[max_ix0[1]]),
      as.integer(rownames(Z_tilde)[max_ix0[2]])
    )

    # input to resulting permutation, and update rows
    pi_result[max_ix[2]] <- max_ix[1]
    X_tilde <- X_tilde[-max_ix0[1],, drop = F]
    Z_tilde <- Z_tilde[-max_ix0[2],, drop = F]
  }

  pi_result
}

#' Permutation to align topics across simulations
#' @importFrom dplyr select select
#' @importFrom tidyr spread
#' @export
experiment_pi <- function(index, dimension, estimate, truth) {
  x <- data.frame(
    "index" = index,
    "dimension" = dimension,
    "estimate" = estimate,
    "truth" = truth
  )

  estimates <- x %>%
    select(index, dimension, estimate) %>%
    spread(index, estimate) %>%
    select(-dimension) %>%
    as.matrix()

  truth <- x %>%
    select(index, dimension, truth) %>%
    spread(index, truth) %>%
    select(-dimension) %>%
    as.matrix()

  match_matrix(estimates, truth)
}

#' Align topics across a full simulations
#' @export
align_experiment <- function(x) {
  pi <- x$pi[[1]]
  if (any(is.na(pi))) {
    warning("not aligning some experiments")
    return(x)
  }

  tmp <- x$estimate
  for (i in seq_along(pi)) {
    x$estimate[x$dimension == pi[i]] <- tmp[x$dimension == i]
  }
  x
}

#' Align posterior samples
#' @importFrom dplyr group_by_ summarise do left_join
#' @importFrom tibble as_data_frame
#' @export
align_posteriors <- function(mcombined) {
  inv_grouping_cols <- c("iteration", "truth", "estimate")
  align_inv_grouping_cols <- c("variable", "dimension", "median_estimate", inv_grouping_cols)

  pi_alignment <- mcombined %>%
    ## first get estimates for beta, using all the iterations
    group_by_(
      .dots = setdiff(colnames(mcombined), c(inv_grouping_cols))
    ) %>%
    summarise(
      truth = truth[1],
      median_estimate = median(estimate)
    ) %>%

    ## then align the estimates with the truth
    group_by_(
      .dots = setdiff(colnames(mcombined), align_inv_grouping_cols)
    ) %>%
    do(pi = experiment_pi(.$variable, .$dimension, .$median_estimate, .$truth))

  ## finally, use these per-experiment pi-hats to perform alignment
  as_data_frame(mcombined) %>%
    left_join(pi_alignment) %>%
    group_by_(
      .dots = setdiff(colnames(mcombined), c("dimension", inv_grouping_cols))
    ) %>%
    do(align_experiment(.))
}

#' Align topics across bootstrap samples
#' @importFrom dplyr group_by_ do left_join
#' @importFrom tibble as_data_frame
#' @export
align_bootstraps <- function(mcombined) {
  inv_grouping_cols <- c("truth", "estimate", "dimension")
  pi_alignment <- mcombined %>%
    group_by_(
      .dots = setdiff(colnames(mcombined), c("variable", inv_grouping_cols))
    ) %>%
    do(pi = experiment_pi(.$variable, .$dimension, .$estimate, .$truth))

  as_data_frame(mcombined) %>%
    left_join(pi_alignment) %>%
    group_by_(
      .dots = setdiff(colnames(mcombined), inv_grouping_cols)
    ) %>%
    do(align_experiment(.))
}

#' Melt reshaped samples
#'
#' While for the scatter / contours figures, it's useful to have the dimensions
#' as separate columns, we'll also want to the melted data when computing
#' explicit errors. This takes the output of reshaped_... and melts it so that
#' it's appropriate for histogramming the errors.
#'
#' @param samples [data.frame] The wide samples data, usually the output of
#'   reshape_all_samples.
#' @return melted_samples [data.frame] The same data as samples, but with
#'   different factor dimensions all stacked.
#' @importFrom tidyr gather separate spread
#' @importFrom dplyr starts_with rename
#' @export
melt_reshaped_samples <- function(samples) {
  samples %>%
    gather(type, val, starts_with("value"), starts_with("truth")) %>%
    separate("type", c("estimate_type", "dimension"), "\\_") %>%
    spread(estimate_type, val) %>%
    rename(estimate = value)
}
